{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "The packages in consileon/data simplify and structurize the development and usage of NLP model.\n",
    "\n",
    "A major part of the development is spent on preparing the input data: Separating \"wanted content\"\n",
    "from \"garbage\", removing unwanted characters, spliting texts into smaller chunks,\n",
    "generating token files for further usage, performing oversampling, ... .\n",
    "\n",
    "These tasks can easily be done using (e.g.) elementary python techniques - but:\n",
    "\n",
    "Doing so\n",
    "- you _repeat yourself_: many boring tasks have to be done again and again,\n",
    "Your end up in a confusing bulk of sample code etc.,\n",
    "- you frequently have to _switch the abstraction level_, e.g. between thinking about the general\n",
    "concept and implementation details,\n",
    "- your _code becomes long and unstructered_ and therefore difficult to maintain (you even might not\n",
    "understand it some time later),\n",
    "- you prevent _knowledge transfer_,\n",
    "- you prevent _modularization_ and _encapsulation_ of frequent tasks (and thus flatten the learning\n",
    "curve of your team).\n",
    "\n",
    "The module `consileon/data` contains a framework to overcome this.\n",
    "\n",
    "Typically, NLP models are generated from one or more text sources which contain (long) sequences\n",
    "of texts.\n",
    "\n",
    "These texts are transformed into other objects which can be handled by NLP algorithms, typically\n",
    "lists of tokens or numbers. These lists are fed into an NLP algorithms.\n",
    "\n",
    "The transformation is typically done in several steps, e.g.\n",
    "\n",
    "- split texts into smaller chunks (sentences, paragraphs),\n",
    "- split chunks of text into tokens (e.g. single words),\n",
    "- bring tokens into a canonical form (transforming to lower case),\n",
    "- filter out unwanted tokens,\n",
    "- \"lemmatization\", map a conjugated or declined form to its base from (imported especially for\n",
    "many non-english languages)\n",
    "- perform (other kinds of) mappings to tokens,\n",
    "- remove \"gargabe\", i.e. artifacts which are contained in the source but which are of need\n",
    "for the specific use case (e.g. ramove tables of numbers from texts when spoken language is\n",
    "required),\n",
    "- append tags to tokens (which specify the source or some semantic information)\n",
    "- choose subsets (e.g.) of the input sequence for development (or other) reasons,\n",
    "- merge several datasources,\n",
    "- and many more.\n",
    "\n",
    "Finally, the target objects of such transformations are \"piped\" into a consuming algorithm which\n",
    "typically generates an NLP model."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}